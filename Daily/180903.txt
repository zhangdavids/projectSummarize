大文件去重排序


#!/bin/bash
lines=$(wc -l $1 | sed 's/ .*//g')
lines_per_file=`expr $lines / 200`
split -d -l $lines_per_file $1 __part_$1

for file in __part_*
do
{
sort $file > sort_$file
} &
done
wait
sort -smu sort_* > $2
rm -f __part_*
rm -f sort_*  

使用方法：./sort_uniq.sh file_to_be_sort file_sorted



使用分治法，分成若干大小的小文件 排序 

再merge所有的小文件 在merge的途中去掉重复的
